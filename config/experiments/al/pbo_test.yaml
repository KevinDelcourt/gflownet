# @package _global_

defaults:
   - override /env: nd_env
   - override /gflownet: trajectorybalance
   - override /loss: trajectorybalance
   - override /proxy: pbo_proxy
   - override /logger: wandb

# Active Learning experiment settings
pbo_al_experiment:
  initial_dataset_size: 50
  problems:
    - name: OneMax
      instances: 
        - id : 3
          problem_sizes: [[5,5,5,5,5]]
          #problem_sizes: [20, [2,2,2,2,2,2,2,2,2,2], [4,4,4,4,4], [5,5,5,5], [10,10], [20]]
#        - id : 2
#          problem_sizes: [10,15]
    - name: LeadingOnes
      instances: 
        - id : 10
          problem_sizes: [[5,5,5,5,5]]
#        - id : 2
#          problem_sizes: [10,15]
  active_learning_models:
    - gflownet
    - random
    - latin_hypercube
    - ucb_rf
  active_learning_iterations: 20
  n_samples_per_al_iteration: 50
  n_al_repeats: 5



# Buffer
buffer:
  test:
    type: random
    n: 100

# GFlowNet hyperparameters
gflownet:
  random_action_prob: 0.1
  optimizer:
    batch_size:
      forward: 10
    lr: 0.0001
    z_dim: 16
    lr_z_mult: 100
    n_train_steps: 1500

# Policy
policy:
  forward:
    type: mlp
    n_hid: 128
    n_layers: 2
  backward:
    shared_weights: True

# WandB
logger:
  do:
    online: False
  lightweight: True
  project_name: "nd_env"
  run_name: "corners"
  tags: 
    - gflownet
    - nd_env
    - corners

# Evaluator
evaluator:
  first_it: True
  period: 500
  n: 1000
  checkpoints_period: 500


# Hydra
hydra:
  run:
    dir: ${user.logdir.root}/pbo_test/${now:%Y-%m-%d_%H-%M-%S_%f}
